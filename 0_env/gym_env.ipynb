{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.调用环境："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.自定义环境："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建一个5X5的网格环境gridworld.py，放到gym\\envs\\classic_control路径下\n",
    "- termianl包括终点和陷阱，修改`self.terminal_rewards`即可修改地图\n",
    "- 使用`set_state()`设置当前状态点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "from numpy import random\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.viewer = None\n",
    "        # state space\n",
    "        self.states = [1, 2, 3, 4, 5,\n",
    "                       6, 7, 8, 9, 10,\n",
    "                       11, 12, 13, 14, 15,\n",
    "                       16, 17, 18, 19, 20,\n",
    "                       21, 22, 23, 24, 25]\n",
    "        # action space\n",
    "        self.actions = ['n', 'e', 's', 'w']\n",
    "        # terminal reward function\n",
    "        self.terminal_rewards = dict()\n",
    "        self.terminal_rewards[25] = 10\n",
    "        self.terminal_rewards[17] = -10\n",
    "        self.terminal_rewards[18] = -10\n",
    "        self.terminal_rewards[19] = -10\n",
    "        self.terminal_rewards[22] = -10\n",
    "        self.terminal_rewards[23] = -10\n",
    "        self.terminal_rewards[24] = -10\n",
    "\n",
    "        self.init_state_action()\n",
    "\n",
    "    def cango_n(self, row, col):\n",
    "        row = row - 1\n",
    "        return 0 <= row <= 4\n",
    "\n",
    "    def cango_s(self, row, col):\n",
    "        row = row + 1\n",
    "        return 0 <= row <= 4\n",
    "\n",
    "    def cango_w(self, row, col):\n",
    "        col = col - 1\n",
    "        return 0 <= col <= 4\n",
    "\n",
    "    def cango_e(self, row, col):\n",
    "        col = col + 1\n",
    "        return 0 <= col <= 4\n",
    "    \n",
    "    def state2rowcol(self, state):\n",
    "        row = (state - 1) // 5\n",
    "        col = (state - 1) %  5\n",
    "        return row, col\n",
    "\n",
    "    def rowcol2state(self, row, col):\n",
    "        return 5*row + col + 1\n",
    "\n",
    "    def init_state_action(self):\n",
    "        # state transition, state-action pair, deterministic here\n",
    "        self.states_actions = dict()\n",
    "        for state in self.states:\n",
    "            if state not in self.terminal_rewards:\n",
    "                self.states_actions[state] = dict()\n",
    "                row, col = self.state2rowcol(state)\n",
    "                if self.cango_n(row, col):\n",
    "                    self.states_actions[state]['n'] = self.rowcol2state(row-1, col)\n",
    "                if self.cango_e(row, col):\n",
    "                    self.states_actions[state]['e'] = self.rowcol2state(row, col+1)\n",
    "                if self.cango_s(row, col):\n",
    "                    self.states_actions[state]['s'] = self.rowcol2state(row+1, col)\n",
    "                if self.cango_w(row, col):\n",
    "                    self.states_actions[state]['w'] = self.rowcol2state(row, col-1)\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "\n",
    "    def step(self, action):\n",
    "        # current state\n",
    "        state = self.state\n",
    "        # 'state-action' transition\n",
    "        if (state in self.states_actions) and (action in self.states_actions[state]):\n",
    "            next_state = self.states_actions[state][action]\n",
    "        # else stay!\n",
    "        else:\n",
    "            next_state = state\n",
    "        self.state = next_state\n",
    "\n",
    "        is_terminal = False\n",
    "        # if is_terminal = True\n",
    "        if self.state in self.terminal_rewards:\n",
    "            r = self.terminal_rewards[self.state]\n",
    "            is_terminal = True\n",
    "        else:\n",
    "            r = -1 # none terminal step reward -1\n",
    "        return next_state, r, is_terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.states[int(random.random() * (len(self.states) ))]\n",
    "        while self.state in self.terminal_rewards:\n",
    "            self.state = self.states[int(random.random() * (len(self.states) - 1))]\n",
    "        return self.state\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        from gym.envs.classic_control import rendering\n",
    "        width = 60\n",
    "        height = 60\n",
    "        edge_x = 0\n",
    "        edge_y = 0\n",
    "        if self.viewer is None:\n",
    "            self.viewer = rendering.Viewer(300, 300)\n",
    "        # terminals\n",
    "        for key, value in self.terminal_rewards.items():\n",
    "            row, col = self.state2rowcol(key)\n",
    "            if value > 0:\n",
    "                self.viewer.draw_polygon([(0, 0), (0, height), (width, height), (width, 0)], filled=True,\n",
    "                                        color=(0, 0, 1.0)).add_attr(rendering.Transform((edge_x + width * col, edge_y + height * (4-row))))\n",
    "            else:\n",
    "                self.viewer.draw_polygon([(0, 0), (0, height), (width, height), (width, 0)], filled=True,\n",
    "                                        color=(0, 0, 0)).add_attr(rendering.Transform((edge_x + width * col, edge_y + height * (4-row))))\n",
    "        # line\n",
    "        for i in range(1, 7):\n",
    "            self.viewer.draw_line((edge_x, edge_y + height * (i - 1)), (edge_x + 5 * width, edge_y + height * (i - 1)))  \n",
    "            self.viewer.draw_line((edge_x + width * (i - 1), edge_y + height * 0),\n",
    "                                  (edge_x + width * (i - 1), edge_y + height * 5))  \n",
    "        # dot\n",
    "        self.x = [edge_x + width * 0.5, edge_x + width * 1.5, edge_x + width * 2.5, edge_x + width * 3.5, edge_x + width * 4.5] * 5\n",
    "        self.y = [edge_y + height * 4.5, edge_y + height * 4.5, edge_y + height * 4.5, edge_y + height * 4.5, edge_y + height * 4.5,\n",
    "                  edge_y + height * 3.5, edge_y + height * 3.5, edge_y + height * 3.5, edge_y + height * 3.5, edge_y + height * 3.5,\n",
    "                  edge_y + height * 2.5, edge_y + height * 2.5, edge_y + height * 2.5, edge_y + height * 2.5, edge_y + height * 2.5,\n",
    "                  edge_y + height * 1.5, edge_y + height * 1.5, edge_y + height * 1.5, edge_y + height * 1.5, edge_y + height * 1.5,\n",
    "                  edge_y + height * 0.5, edge_y + height * 0.5, edge_y + height * 0.5, edge_y + height * 0.5, edge_y + height * 0.5]\n",
    "        self.viewer.draw_circle(18, color=(1.0, 0.0, 0.0)).add_attr(\n",
    "            rendering.Transform(translation=(self.x[self.state - 1], self.y[self.state - 1])))\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在gym\\envs\\classic_control下的初始化文件_init_.py中添加"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from gym.envs.classic_control.gridworld import GridWorldEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在gym\\envs下的初始化文件_init_.py中添加"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "register (\n",
    "    id= 'GridWorld-v0',\n",
    "    entry_point='gym.envs.classic_control:GridWorldEnv', \n",
    "    max_episode_steps=200, \n",
    "    reward_threshold=100.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用GridWorld环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_state:4\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:4, reward:-1, is_terminal:False\n",
      "next_state:5, reward:-1, is_terminal:False\n",
      "next_state:5, reward:-1, is_terminal:False\n",
      "next_state:4, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:8, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:2, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:3, reward:-1, is_terminal:False\n",
      "next_state:4, reward:-1, is_terminal:False\n",
      "next_state:4, reward:-1, is_terminal:False\n",
      "next_state:4, reward:-1, is_terminal:False\n",
      "next_state:5, reward:-1, is_terminal:False\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "env = gym.make('GridWorld-v0')\n",
    "env.reset()\n",
    "for _ in range(20):\n",
    "    env.render()\n",
    "    if _ == 0:\n",
    "        print(\"init_state:{}\".format(env.state))\n",
    "    next_state, reward, is_terminal,info = env.step(env.actions[int(random.random()*len(env.actions))]) # take a random action\n",
    "    print(\"next_state:{}, reward:{}, is_terminal:{}\".format(next_state, reward, is_terminal))\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
